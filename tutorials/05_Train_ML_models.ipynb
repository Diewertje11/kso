{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34ee668b",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://panoptes-uploads.zooniverse.org/project_avatar/86c23ca7-bbaa-4e84-8d8a-876819551431.png\" type=\"image/png\" height=100 width=100>\n",
    "</img>\n",
    "<h1 align=\"right\">KSO Tutorials #5: Train ML models</h1>\n",
    "<h3 align=\"right\">Written by the KSO Team</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde301e",
   "metadata": {},
   "source": [
    "# 1. Set up and requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbde05d8",
   "metadata": {},
   "source": [
    "### Install and import Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a108b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally... you're good to go!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    import os\n",
    "\n",
    "    IN_COLAB = True\n",
    "    print(\"Running in Colab...\")\n",
    "\n",
    "    # Clone repo\n",
    "    !git clone --recurse-submodules https://github.com/ocean-data-factory-sweden/koster_yolov4.git\n",
    "    !pip install -q --upgrade pip\n",
    "    !pip install -qr koster_yolov4/requirements.txt\n",
    "    !pip install -qr koster_yolov4/yolov5_tracker/requirements.txt\n",
    "\n",
    "    # Fix libmagic issue\n",
    "    !apt-get -qq update && apt-get -qq install -y libmagic-dev > /dev/null\n",
    "\n",
    "    # Replace upsampling script with custom version\n",
    "    os.chdir(\"koster_yolov4/tutorials\")\n",
    "    !mv ../src/upsampling.py /usr/local/lib/python3.7/dist-packages/torch/nn/modules/upsampling.py\n",
    "\n",
    "    # Replace nearest neighbours script with custom version (due to relative path issue)\n",
    "    !cp ../src/multi_tracker_zoo.py ../yolov5_tracker/trackers/strong_sort/multi_tracker_zoo.py\n",
    "\n",
    "    # Enable external widgets\n",
    "    from google.colab import output\n",
    "\n",
    "    output.enable_custom_widget_manager()\n",
    "\n",
    "    # Ensure widgets are shown properly\n",
    "    !jupyter nbextension enable --user --py widgetsnbextension\n",
    "    !jupyter nbextension enable --user --py jupyter_bbox_widget\n",
    "\n",
    "    print(\"All packages are installed and ready to go!\")\n",
    "    try:\n",
    "        clear_output()\n",
    "        print(\"All packages are installed and ready to go!\")\n",
    "    except:\n",
    "        clear_output()\n",
    "        print(\"There have been some issues installing the packages!\")\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    import sys\n",
    "    import pkgutil\n",
    "\n",
    "    if pkgutil.find_loader(\"torch\") is None:\n",
    "        !pip install -q --upgrade pip\n",
    "        !pip install -q torch==1.8.0 torchvision==0.9.0\n",
    "\n",
    "    # Replace nearest neighbours script with custom version (due to relative path issue)\n",
    "    !cp ../src/multi_tracker_zoo.py ../yolov5_tracker/trackers/strong_sort/multi_tracker_zoo.py\n",
    "    # Ensure widgets are shown properly\n",
    "    !jupyter nbextension enable --user --py widgetsnbextension\n",
    "    !jupyter nbextension enable --user --py jupyter_bbox_widget\n",
    "    clear_output()\n",
    "    print(\"Running locally... you're good to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da34a7b",
   "metadata": {
    "id": "8x8PxQNI0UKI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages loaded successfully\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecf8312d8334c0c93929e642b4cf866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Required model type:', layout=Layout(width='max-content'), options=(('Object Detection (…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the directory of the libraries\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Enables testing changes in utils\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import required modules\n",
    "from pathlib import Path\n",
    "from ipyfilechooser import FileChooser\n",
    "import kso_utils.tutorials_utils as t_utils\n",
    "import kso_utils.project_utils as p_utils\n",
    "import kso_utils.server_utils as s_utils\n",
    "import kso_utils.t5_utils as t5\n",
    "import wandb\n",
    "\n",
    "clear_output()\n",
    "print(\"Packages loaded successfully\")\n",
    "\n",
    "# Select the model type for training\n",
    "model_type = t5.choose_model_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "583fc40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjannesg\u001b[0m (\u001b[33mkoster\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image classification model loaded\n"
     ]
    }
   ],
   "source": [
    "# Model-specific imports\n",
    "if model_type.value == 1:\n",
    "    import yolov5.train as train\n",
    "    import yolov5.detect as detect\n",
    "    import yolov5.val as val\n",
    "\n",
    "    print(\"Object detection model loaded\")\n",
    "elif model_type.value == 2:\n",
    "    import yolov5.classify.train as train\n",
    "    import yolov5.classify.predict as detect\n",
    "    import yolov5.classify.val as val\n",
    "\n",
    "    print(\"Image classification model loaded\")\n",
    "elif model_type.value == 3:\n",
    "    import yolov5.segment.train as train\n",
    "    import yolov5.segment.predict as detect\n",
    "    import yolov5.segment.val as val\n",
    "\n",
    "    print(\"Image segmentation model loaded\")\n",
    "else:\n",
    "    print(\"Invalid model specification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996c27bf",
   "metadata": {
    "id": "mcFpT7njzfGw"
   },
   "source": [
    "# 2. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4aa00cf",
   "metadata": {},
   "source": [
    "🔴 <span style=\"color:red\">&nbsp;NOTE: To be able to train your own models, you will need access to the Koster WANDB group. You may request this access by contacting jurie.germishuys@combine.se. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8465bcc6",
   "metadata": {
    "id": "ZZWAWkVZzfGr"
   },
   "source": [
    "### Choose your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79a20a1a",
   "metadata": {
    "id": "ZI0XH96WzfGs"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35a3cf5665d4129a44017e9e703cd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Project:', options=('Template project', 'Koster_Seafloor_Obs', 'Spyfish_Aotearoa', 'SGU'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project_name = t_utils.choose_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7f7fcf4",
   "metadata": {
    "id": "o8ShAbg3zfGs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:SGU loaded succesfully\n",
      "SGU loaded succesfully\n"
     ]
    }
   ],
   "source": [
    "project = p_utils.find_project(project_name=project_name.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "135632f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:No download method implemented for this data\n",
      "No download method implemented for this data\n"
     ]
    }
   ],
   "source": [
    "# Only for Template Project (downloading prepared data)\n",
    "s_utils.get_ml_data(project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d2dc7b",
   "metadata": {
    "id": "m7EK4BXjzfGu"
   },
   "source": [
    "### Configure data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef4c3818",
   "metadata": {
    "id": "HvaEo7mjzfGv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/std.py:725: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc3313e928c47a2b6c1719b0447250e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/mimer/NOBACKUP/groups/snic2022-22-1210/KSO_SGU_pz/sgu_samples', filename='', title='HTML(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify path containing the images and labels folders.\n",
    "output_folder = t_utils.choose_folder(\n",
    "    project.photo_folder if not project.photo_folder == \"None\" else \".\", \"output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e1f430",
   "metadata": {},
   "source": [
    "🔴 <span style=\"color:red\">&nbsp;NOTE: Each model type requires a specific folder structure to be in place. To be able to train your own Object Detection models, your data_path must contain a yml file for data and hyperparameters. See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data#11-create-datasetyaml. For image classification models, there should be 3 folders (train, val, test) each containing images in class_name folders. For segmentation models, polygon coordinates are also required. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b456358c",
   "metadata": {
    "id": "Jt2PIFLdzfGw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Paths do not need to be changed for this model type.\n",
      "Paths do not need to be changed for this model type.\n"
     ]
    }
   ],
   "source": [
    "# Fix important paths\n",
    "data_path, hyps_path = t5.setup_paths(output_folder.selected, model_type.value)\n",
    "project_path = str(Path(output_folder.selected, project.Project_name.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e154a757",
   "metadata": {},
   "source": [
    "### Choose a suitable experiment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "487f6c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b388fffda74d6f8058fefb756dfa85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='exp_name', description='Experiment name:', placeholder='Choose an experiment name', style=Descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_name = t5.choose_experiment_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03895435",
   "metadata": {
    "id": "rTb9DFFWzfGw"
   },
   "source": [
    "### Choose model to use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b74c787d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3408517a624d13a0140fc36bada089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/mimer/NOBACKUP/groups/snic2022-22-1210/KSO_SGU_pz/sgu_samples', filename='', title='HTML(va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify path to download baseline model\n",
    "download_folder = t_utils.choose_folder(\n",
    "    project.photo_folder if not project.photo_folder == \"None\" else \".\",\n",
    "    \"model download\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a60625fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ff714eaa74422cbcd25527e1e0b286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select model:', layout=Layout(width='50%'), options=(('yolov5m-classifier', <ArtifactCol…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672d414b6b694a97bf10107aba72a733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = t5.choose_baseline_model(download_folder.selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa1154",
   "metadata": {
    "id": "rTb9DFFWzfGw"
   },
   "source": [
    "### Train model with given configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "690c07db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724fcf7385c147ed93c3f516f180035e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatLogSlider(value=1.0, base=2.0, description='Batch size:', max=10.0, readout_format='d', st…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size, epochs = t5.choose_train_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3f4b71e",
   "metadata": {
    "id": "JtoEszUszfGw",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:yolov5:\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=/mimer/NOBACKUP/groups/snic2021-6-9/tmp_dir/sgu_out_split_224_0.8_1337/yolov5m-cls.pt, data=/mimer/NOBACKUP/groups/snic2021-6-9/tmp_dir/sgu_out_split_224_0.8_1337/, epochs=10, batch_size=32, imgsz=224, nosave=False, cache=None, device=, workers=4, project=sgu, name=classification_model, exist_ok=False, pretrained=True, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1, entity=koster\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=/mimer/NOBACKUP/groups/snic2021-6-9/tmp_dir/sgu_out_split_224_0.8_1337/yolov5m-cls.pt, data=/mimer/NOBACKUP/groups/snic2021-6-9/tmp_dir/sgu_out_split_224_0.8_1337/, epochs=10, batch_size=32, imgsz=224, nosave=False, cache=None, device=, workers=4, project=sgu, name=classification_model, exist_ok=False, pretrained=True, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1, entity=koster\n",
      "INFO:yolov5:\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 295 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 295 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
      "INFO:yolov5:\u001b[31m\u001b[1mrequirements:\u001b[0m tqdm>=4.64.0 not found and is required by YOLOv5, attempting auto-update...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m tqdm>=4.64.0 not found and is required by YOLOv5, attempting auto-update...\n",
      "WARNING:yolov5:\u001b[31m\u001b[1mrequirements:\u001b[0m Command 'pip install \"tqdm>=4.64.0\" ' returned non-zero exit status 1.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Command 'pip install \"tqdm>=4.64.0\" ' returned non-zero exit status 1.\n",
      "INFO:yolov5:\u001b[31m\u001b[1mrequirements:\u001b[0m tensorboard>=2.4.1 not found and is required by YOLOv5, attempting auto-update...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m tensorboard>=2.4.1 not found and is required by YOLOv5, attempting auto-update...\n",
      "WARNING:yolov5:\u001b[31m\u001b[1mrequirements:\u001b[0m Command 'pip install \"tensorboard>=2.4.1\" ' returned non-zero exit status 1.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Command 'pip install \"tensorboard>=2.4.1\" ' returned non-zero exit status 1.\n",
      "INFO:yolov5:YOLOv5 🚀 2022-12-1 Python-3.8.8 torch-1.9.0+cu111 CUDA:0 (NVIDIA A40, 45483MiB)\n",
      "\n",
      "YOLOv5 🚀 2022-12-1 Python-3.8.8 torch-1.9.0+cu111 CUDA:0 (NVIDIA A40, 45483MiB)\n",
      "\n",
      "INFO:yolov5:\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir sgu', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir sgu', view at http://localhost:6006/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mimer/NOBACKUP/groups/snic2021-6-9/wandb/run-20230214_174303-fextd983</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/koster/sgu/runs/fextd983' target=\"_blank\">classification_model</a></strong> to <a href='https://wandb.ai/koster/sgu' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/koster/sgu' target=\"_blank\">https://wandb.ai/koster/sgu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/koster/sgu/runs/fextd983' target=\"_blank\">https://wandb.ai/koster/sgu/runs/fextd983</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:yolov5:Model summary: 212 layers, 11683045 parameters, 11683045 gradients, 30.9 GFLOPs\n",
      "Model summary: 212 layers, 11683045 parameters, 11683045 gradients, 30.9 GFLOPs\n",
      "INFO:yolov5:\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 46 weight(decay=0.0), 47 weight(decay=5e-05), 47 bias\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 46 weight(decay=0.0), 47 weight(decay=5e-05), 47 bias\n",
      "WARNING:yolov5:WARNING: label smoothing 0.1 requires torch>=1.10.0\n",
      "WARNING: label smoothing 0.1 requires torch>=1.10.0\n",
      "INFO:yolov5:Image sizes 224 train, 224 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1msgu/classification_model11\u001b[0m\n",
      "Starting /mimer/NOBACKUP/groups/snic2021-6-9/tmp_dir/sgu_out_split_224_0.8_1337/yolov5m-cls.pt training on /mimer/NOBACKUP/groups/snic2021-6-9/tmp_dir/sgu_out_split_224_0.8_1337 dataset with 5 classes for 10 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss   test_loss    top1_acc    top5_acc\n",
      "Image sizes 224 train, 224 test\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1msgu/classification_model11\u001b[0m\n",
      "Starting /mimer/NOBACKUP/groups/snic2021-6-9/tmp_dir/sgu_out_split_224_0.8_1337/yolov5m-cls.pt training on /mimer/NOBACKUP/groups/snic2021-6-9/tmp_dir/sgu_out_split_224_0.8_1337 dataset with 5 classes for 10 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss   test_loss    top1_acc    top5_acc\n",
      "      1/10      1.9G       0.894       0.793       0.674           1: 100%|██████████| 1043/1043 [01:45<00:00,  9.89it/s]\n",
      "      2/10      1.9G       0.774       0.753        0.69           1: 100%|██████████| 1043/1043 [01:42<00:00, 10.14it/s]\n",
      "      3/10      1.9G       0.737       0.893       0.642           1: 100%|██████████| 1043/1043 [01:44<00:00, 10.02it/s]\n",
      "      4/10      1.9G       0.698                                    :  83%|████████▎ | 870/1043 [01:22<00:16, 10.76it/s]../yolov5/classify/train.py:190: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)  # clip gradients\n",
      "      4/10      1.9G         0.7       0.739       0.698           1: 100%|██████████| 1043/1043 [01:44<00:00, 10.02it/s]\n",
      "      5/10      1.9G       0.663       0.729       0.698           1: 100%|██████████| 1043/1043 [01:41<00:00, 10.27it/s]\n",
      "      6/10      1.9G       0.618       0.697       0.719           1: 100%|██████████| 1043/1043 [01:43<00:00, 10.06it/s]\n",
      "      7/10      1.9G       0.551       0.695       0.716           1: 100%|██████████| 1043/1043 [01:43<00:00, 10.12it/s]\n",
      "      8/10      1.9G       0.441       0.747       0.715           1: 100%|██████████| 1043/1043 [01:42<00:00, 10.17it/s]\n",
      "      9/10      1.9G       0.293        0.92       0.712           1: 100%|██████████| 1043/1043 [01:43<00:00, 10.04it/s]\n",
      "     10/10      1.9G       0.155        1.17       0.705           1: 100%|██████████| 1043/1043 [01:42<00:00, 10.16it/s]\n",
      "INFO:yolov5:\n",
      "Training complete (0.288 hours)\n",
      "Results saved to \u001b[1msgu/classification_model11\u001b[0m\n",
      "Predict:         python classify/predict.py --weights sgu/classification_model11/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights sgu/classification_model11/weights/best.pt --data /mimer/NOBACKUP/groups/snic2021-6-9/tmp_dir/sgu_out_split_224_0.8_1337\n",
      "Export:          python export.py --weights sgu/classification_model11/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'sgu/classification_model11/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n",
      "\n",
      "Training complete (0.288 hours)\n",
      "Results saved to \u001b[1msgu/classification_model11\u001b[0m\n",
      "Predict:         python classify/predict.py --weights sgu/classification_model11/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights sgu/classification_model11/weights/best.pt --data /mimer/NOBACKUP/groups/snic2021-6-9/tmp_dir/sgu_out_split_224_0.8_1337\n",
      "Export:          python export.py --weights sgu/classification_model11/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'sgu/classification_model11/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if model_type.value == 1:\n",
    "    train.run(\n",
    "        entity=\"koster\",\n",
    "        data=data_path,\n",
    "        hyp=hyps_path,\n",
    "        weights=weights.artifact_path,\n",
    "        project=os.path.basename(project_path).replace(\" \", \"_\").lower(),\n",
    "        name=exp_name.value,\n",
    "        img_size=[720, 540],\n",
    "        batch_size=int(batch_size.value),\n",
    "        epochs=epochs.value,\n",
    "        workers=1,\n",
    "        single_cls=False,\n",
    "        cache_images=True,\n",
    "    )\n",
    "elif model_type.value == 2:\n",
    "    train.run(\n",
    "        entity=\"koster\",\n",
    "        data=data_path,\n",
    "        model=weights.artifact_path,\n",
    "        project=os.path.basename(project_path).replace(\" \", \"_\").lower(),\n",
    "        name=exp_name.value,\n",
    "        imgsz=224,\n",
    "        batch_size=int(batch_size.value),\n",
    "        epochs=10,\n",
    "        workers=4,\n",
    "    )\n",
    "else:\n",
    "    print(\"Segmentation model training not yet supported.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da9c187",
   "metadata": {
    "id": "PRXru5arzfGw"
   },
   "source": [
    "# 3. Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c271179",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_thres = t5.choose_eval_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3796c0c0",
   "metadata": {
    "id": "Erw0xEw3zfGw"
   },
   "outputs": [],
   "source": [
    "# Choose model\n",
    "eval_model = FileChooser(project_path)\n",
    "display(eval_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc93fef7",
   "metadata": {
    "id": "Fdr9K3nHzfGw"
   },
   "outputs": [],
   "source": [
    "# Find trained model weights\n",
    "tuned_weights = f\"{Path(project_path, eval_model.selected, 'weights', 'best.pt')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745ab8cf",
   "metadata": {
    "id": "_Dx9tD3bzfGx"
   },
   "outputs": [],
   "source": [
    "# Evaluate YOLO Model on Unseen Test data\n",
    "val.run(\n",
    "    data=data_path,\n",
    "    weights=tuned_weights,\n",
    "    conf_thres=conf_thres.value,\n",
    "    imgsz=640 if model_type.value == 1 else 224,\n",
    "    half=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c81dd91",
   "metadata": {
    "id": "5VGC_NMazfGx"
   },
   "source": [
    "# (Optional) : 4. Enhance annotations using trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1597f06",
   "metadata": {},
   "source": [
    "Enhancement uses the trained model to increase the amount of annotations in the training data. This should only be done in cases where it is absolutely necessary as bad predictions lead to worse predictions when used to train the next iteration of the model. \n",
    "\n",
    "\n",
    "🔴 <span style=\"color:red\">&nbsp;NOTE: We recommend using a relatively high confidence threshold when enhancing trained models as low confidence predictions could significantly impact the quality of your annotated data. This is currently only available for object detection models.  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcfa4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "eh_conf_thres = t5.choose_eval_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31741f25",
   "metadata": {
    "id": "M7kV7K2EzfGx"
   },
   "outputs": [],
   "source": [
    "if model_type.value == 1:\n",
    "    detect.run(\n",
    "        weights=tuned_weights,\n",
    "        source=output_folder.selected + \"/images\",\n",
    "        imgsz=[640, 640],\n",
    "        conf_thres=eh_conf_thres.value,\n",
    "        save_txt=True,\n",
    "    )\n",
    "elif model_type.value == 2:\n",
    "    print(\"Enhancements not supported for image classification models at this time.\")\n",
    "else:\n",
    "    print(\"Enhancements not supported for segmentation models at this time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea2104",
   "metadata": {},
   "source": [
    "### Choose run to use as enhanced annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015b7982",
   "metadata": {
    "id": "67uHzz1TzfGx"
   },
   "outputs": [],
   "source": [
    "runs = FileChooser(\".\")\n",
    "display(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cbc146",
   "metadata": {
    "id": "h-sCJ8FZzfGx"
   },
   "outputs": [],
   "source": [
    "if model_type.value == 1:\n",
    "    !mv {output_folder}\"/labels\" {output_folder}\"/labels_org\"\n",
    "    !mv {runs.selected}\"/labels\" {output_folder}\"/labels\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaee580",
   "metadata": {},
   "source": [
    "#### Once you have moved the new labels to the original label location, you can return to Step 2 and train your model again. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c58523",
   "metadata": {},
   "source": [
    "🔴 <span style=\"color:red\">&nbsp;NOTE: Run this cell to complete WANDB run, OR else artifacts will not be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4dc3cdde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/0</td><td>█▇▅▄▂▁</td></tr><tr><td>metrics/accuracy_top1</td><td>▁▂▆▅██</td></tr><tr><td>metrics/accuracy_top5</td><td>▁▁▁▁▁▁</td></tr><tr><td>test/loss</td><td>█▇▃▄▁▁</td></tr><tr><td>train/loss</td><td>█▅▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/0</td><td>0.00041</td></tr><tr><td>metrics/accuracy_top1</td><td>0.69013</td></tr><tr><td>metrics/accuracy_top5</td><td>1.0</td></tr><tr><td>test/loss</td><td>0.76902</td></tr><tr><td>train/loss</td><td>0.74242</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classification_model</strong> at: <a href='https://wandb.ai/koster/sgu/runs/ktktpx3b' target=\"_blank\">https://wandb.ai/koster/sgu/runs/ktktpx3b</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/mimer/NOBACKUP/groups/snic2021-6-9/wandb/run-20230214_172734-ktktpx3b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27308b76",
   "metadata": {
    "id": "8umCRoDozfGx"
   },
   "outputs": [],
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOpvN5FDAqS18FP36kGBtHm",
   "collapsed_sections": [],
   "name": "Train_YOLO_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9f0064b85a3bc365415745ead9abb78ac240c43fe3a2a9861333bea64f4ce941"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
